{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Load Performance Benchmarks\n",
    "In this notebook, two save file formats are compared against each other for their read/write performace. The version one format will write each \"population\" in an optimization history object as its own HDF5 group. The version two format will instead merge all decision variables, objectives, and constraints into a single large array before saving. This should be more performant by histting the HDF5 API fewer times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from paretobench.containers import Experiment\n",
    "import tempfile\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment to play around with\n",
    "exp = Experiment.from_random(5*32, 20, 10, 30, 2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_save_load(version):\n",
    "    with tempfile.TemporaryDirectory() as dir:\n",
    "        # Get the start time\n",
    "        start_t = time.perf_counter()\n",
    "        \n",
    "        # Save it\n",
    "        exp.save(os.path.join(dir, 'test.h5'), version=version)\n",
    "        save_t = time.perf_counter() - start_t\n",
    "        \n",
    "        # Load it\n",
    "        Experiment.load(os.path.join(dir, 'test.h5'), version=version)\n",
    "        load_t = time.perf_counter() - start_t - save_t\n",
    "        \n",
    "        # Report the timings\n",
    "        return {'save_t': save_t, 'load_t': load_t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version one timings: save=1.29s, load=1.08s\n"
     ]
    }
   ],
   "source": [
    "# Measure times for version one format\n",
    "runs = [time_save_load(1) for _ in range(10)]\n",
    "load_t = np.mean([r['load_t'] for r in runs])\n",
    "save_t = np.mean([r['save_t'] for r in runs])\n",
    "print(f'Version one timings: save={save_t:.2f}s, load={load_t:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version two timings: save=0.13s, load=0.14s\n"
     ]
    }
   ],
   "source": [
    "# Measure times for version two format\n",
    "runs = [time_save_load(2) for _ in range(10)]\n",
    "load_t = np.mean([r['load_t'] for r in runs])\n",
    "save_t = np.mean([r['save_t'] for r in runs])\n",
    "print(f'Version two timings: save={save_t:.2f}s, load={load_t:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmoga",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
